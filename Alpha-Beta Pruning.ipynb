{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0113fec",
   "metadata": {},
   "source": [
    "# Project: Exploring Search Trees and Alpha-Beta Pruning with Chess\n",
    "\n",
    "## Machine Learning, Fall 2021\n",
    "\n",
    "### Name: Davin Jeong\n",
    "\n",
    "### Sources\n",
    "* [Alpha-beta Pruning in Chess Engines](https://umm-csci.github.io/senior-seminar/seminars/spring2017/marckel.pdf), by Otto Marckel\n",
    "* [The Anatomy of a Chess AI](https://medium.com/@SereneBiologist/the-anatomy-of-a-chess-ai-2087d0d565), by Levi Walker\n",
    "\n",
    "### Objective: \n",
    "**A Chess AI that can learn from a database of positions in order to suggest strong moves in new positions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28f1c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chess # Chess library for move generation and move validation: https://python-chess.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92a069",
   "metadata": {},
   "source": [
    "## General Approach\n",
    "Chess is estimated to have about $10^{120}$ games. To put things into perspective, there are about $10^{80}$ atoms in the observable universe. Its complexity and popularity as a sport has made it a popular subject of computer science research. Some approaches are listed below: \n",
    "- An Explicit Algorithm: It might be possible, in theory, to mimic the way humans play by comnining analysis, strategy, and tactics to determine the next move. However, in practice, we cannot program the complex computations humans perform intuitively. \n",
    "- Brute Force: The fastest supercomputer performs [\"quadrillions of floating point operations per second.\"](https://asia.nikkei.com/Business/Technology/Japan-s-Fugaku-keeps-position-as-world-s-fastest-supercomputer) For reference, one quadrillion is $10^{15}$. Clearly, it is completely impractical, not to mention unethical, to try to brute force chess. \n",
    "- Search Tree: A third approach is best exemplified by the commonly-heard phrase \"looking ahead *x* moves.\" Just as human players create plans by anticipating future moves, evaluating their outcomes, and following the path with most potential, search trees look a limited number of moves ahead and calculate the move that is most likely to result in a win. \n",
    "\n",
    "The Alpha-Beta Search Algorithm, proposed by around 1958, was one of the first autonomous chess-playing algorithms. At its core, it relies on a combination of an evaluator function and a search tree. We will focus on this algorithm in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883d19e",
   "metadata": {},
   "source": [
    "## Evaluating Positions\n",
    "At their base, search tree algorithms rely on an evaluator function: some way of quantifying the \"goodness\" of a position. This is crucial since we need some way of looking at a chain of moves and identifying how \"good,\" or likely to lead to a win, for a player.\n",
    "\n",
    "Evaluator functions can employ any number of approaches. The general idea is to map the influence of certain features on a position's \"goodness.\" These features could be determined however we please, whether it be through heuristics/analysis or using unsupervised, supervised, or reinforcment learning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e71857fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate based on material\n",
    "\n",
    "piece_points = {'R' : 5, 'r' : 5, \n",
    "                'N' : 3, 'n' : 3 , \n",
    "                'B' : 3, 'b' : 3,\n",
    "                'Q' : 9, 'q' : 9, \n",
    "                'P' : 1, 'p' : 1,\n",
    "                'K' : 0, 'k' : 0,\n",
    "                '.' : 0, } \n",
    "def evaluate(board):\n",
    "    whiteMaterial = blackMaterial = 0 \n",
    "    \n",
    "    rows = str(board).split('\\n')\n",
    "    for row in rows:\n",
    "        for piece in row.split(' '):\n",
    "            #print(piece)\n",
    "            if piece.isalpha() and piece.isupper():\n",
    "                whiteMaterial += piece_points[piece]\n",
    "            else:\n",
    "                blackMaterial += piece_points[piece]  \n",
    "    return whiteMaterial - blackMaterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b02a585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r . b q k b . r\n",
      "p p p p . Q p p\n",
      ". . n . . n . .\n",
      ". . . . p . . .\n",
      ". . B . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B . K . N R\n",
      "Material Evaluation: 1\n"
     ]
    }
   ],
   "source": [
    "# Test Above Code\n",
    "\n",
    "board = chess.Board(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 0 4\") # https://tynedalechess.wordpress.com/2017/11/05/fen-strings-explained/\n",
    "print(board)\n",
    "\n",
    "print(f\"Material Evaluation: {evaluate(board)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62777b8f",
   "metadata": {},
   "source": [
    "**TODO: Create an evaluation function using supervised learning on [Chess Evaluations](https://www.kaggle.com/ronakbadhe/chess-evaluations/code)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41de2d",
   "metadata": {},
   "source": [
    "## Search Trees\n",
    "\n",
    "Search trees are used to model the outcomes of possible moves:\n",
    "\n",
    "![title](https://www.sites.google.com/site/qgchess/_/rsrc/1467139373444/chess-algorithms/minmaxtree.JPG)\n",
    "**Image from [QGChess](https://www.sites.google.com/site/qgchess/chess-algorithms)**\n",
    "\n",
    "In the above diagram, we see a search tree rooted at the starting position of chess (A). Each of it's children nodes (B, C, D) represent potential moves that white can play. The children nodes of those children (E, F) represent black's potential responses. We can use this structure to look a limited number of moves into the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cae4ff",
   "metadata": {},
   "source": [
    "## Minimax Search\n",
    "\n",
    "Now that we have a way of evaluating a position, our material evaluation, and modelling the possible variations stemming from it, the search tree, we need to combine these to search the tree and make decisions. One such algorithm is Minimax. \n",
    "\n",
    "For Minimax, we label one player \"the maximizer\" and the other \"the minimizer.\" These names stem from the fact that our evaluation tells us how much higher white's score is over black's: white would want to maximize this score, and black would want to minimize it. \n",
    "\n",
    "Minimax assumes both players optimally and tries to optimise the worst possible case that could result from the current player's move. \n",
    "\n",
    "![title](https://www.baeldung.com/wp-content/uploads/2017/07/minimax.png)\n",
    "**Image from [Introduction to Minimax](https://www.baeldung.com/java-minimax-algorithm)**\n",
    "\n",
    "For instance, consider the above image. The search tree is built out from our root node, with each following node representing possible moves of their parent. The leaf nodes represent all the possible positions after a certain amount of moves. For our Chess Bot, we would store the positions' details, and we would have more children per node (about 35). Here, we are trying to illustrate Minimax, so we only see positions' evaluations. \n",
    "\n",
    "Here's a breakdown of the algorithm:\n",
    "1. Build out the search tree, evaluate leaf nodes\n",
    "2. Build up from there recursively. Each level is either white's or black's turn. White tries to maximize the score by picking the highest evaluation child. Black tries to minimize the score by picking the lowest evaluation child.\n",
    "3. In the end, we realize that white should pick the move returning the 4 evaluation (the leaf node 2nd from the right), as this is the maximium position it can guarantee. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b6da0",
   "metadata": {},
   "source": [
    "## Alpha-Beta Pruning\n",
    "\n",
    "As you might have guessed, exhausting every position using a search tree, even to a limited depth, is a time-consuming process in a game as complex as chess is. As a result, people have developed many optimizations over the years to reduce the positions we have to evaluate. One of them is Alpha-Beta Pruning. \n",
    "\n",
    "This algorithm builds upon Minimax by elaborating on the premise that each player will play optimally. We explore the tree in a depth-first search manner. After following a sequence of moves down to the leaf node, we employ the same bottom up approach as Minimax, with the added component of variables *Alpha* and *Beta*. Alpha represents the best guaranteed option for the maximizing player in the current branch, and beta represents the best guaranteed option for the minimizing player in the current branch. We use these to prune branches that won't be explored, as they're necessarily suboptimal.\n",
    "\n",
    "![title](https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/05/08235613/Blog-8-5-2020-04-1024x598.jpg)\n",
    "**Image from [Alpha Beta Pruning in AI](https://www.mygreatlearning.com/blog/alpha-beta-pruning-in-ai/)**\n",
    "\n",
    "Here's a breakdown of the algorithm:\n",
    "1. Depth-first search to a leaf node. Let's say we take A -> B -> D.\n",
    "2. At each node, store the alpha and beta values. At D, the maximizer can guarantee an evaluation of so alpha is 3, but the minimizer cannot guarantee anything (it has no input), so the beta is infinity.\n",
    "3. After we calculate this for one node, we travel back up the tree and update our beta and alpha values. So, based on our current knowledge, the maximizer can guarantee an evaluation of 3 at B, and the minimizer can guarantee an evaluation of 3 if it chooses the previously explored path.\n",
    "4. In-line with normal dfs, we explore another path. We go down from node B to E, and check the first position. Already, the maximizer can force a position of 5. This is already higher than 3 from the previous branch, so the minimizer must force the D branch. We need not further evaluate from the E node. \n",
    "5. Repeat this procedure for all other nodes. Eventually, we'll have the best guaranteed outcome for white in the root node, but we will have obtained it by evaluating less positions (using the Alpha-Beta pruning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26815197",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pseudocode: \n",
    "\n",
    "def dfs(board, height, alpha, beta, alphaTurn):\n",
    "   if height==0 or board.isendofgame():\n",
    "      return eval(board)\n",
    "   else if(alphaTurn):\n",
    "      maxEval = -infinity\n",
    "      for each continuation:\n",
    "         eval = dfs(board, height - 1, alpha, beta, False)\n",
    "         maxEval = max(maxEval, eval)\n",
    "         alpha = max(alpha, eval)\n",
    "         # Alpha at this node will be >= its current value. If this is higher than a guaranteed beta, black will go for the other option in the previous turn.\n",
    "         if alpha >= beta: \n",
    "            break\n",
    "      return maxEval\n",
    "   else:\n",
    "      minEval = +infinity\n",
    "      for each continuation:\n",
    "         eval = dfs(board, height - 1, alpha, beta, True)\n",
    "         minEval = min(minEval, eval)\n",
    "         beta = min(beta, eval)\n",
    "         # Beta at this node will be <= its current value. If this is lower than a guaranteed alpha, white will go for the other option in the previous turn.\n",
    "        if beta <= alpha:\n",
    "           break\n",
    "       return minEval\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
